{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K09VjeSh7CiJ",
        "outputId": "837510cd-c156-496d-dce3-cae2b6bfb67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyMJMhmL7INn",
        "outputId": "ce90a730-8389-46cc-cdc2-cea6bcbf79b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ac61e448-ce6f-a21f-e52b-0eda933f7c22)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG3ypsnx84Um"
      },
      "source": [
        "Get Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bc0v5Q4284BD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "def upload_imgs(img_folder):\n",
        "\n",
        "  img_array = []\n",
        "  for file in os.listdir(img_folder): \n",
        "    if len(file) >3 and file[:3] != \"img\":\n",
        "      print(file[:2])\n",
        "      continue\n",
        "\n",
        "    img_path = os.path.join(img_folder, file)\n",
        "    #print('IMAGE PATH: ', img_path)\n",
        "    # image = np.array(Image.open(img_path), dtype = int)/255\n",
        "    image = Image.open(img_path)\n",
        "    image = image.resize((224,224), Image.LANCZOS)\n",
        "    # image = image.astype('int64')\n",
        "    img_array.append(image)\n",
        "    #print(image.dtype)\n",
        "      \n",
        "  print('UPLOAD DONE')\n",
        "  return img_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4gF6If34sbL"
      },
      "source": [
        "Augmentation and PreProcesssing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "btFjrtic4r0B"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def augment(imgs):\n",
        "  imgs_copy = imgs\n",
        "\n",
        "  # vector of PIL imgs\n",
        "  augment1 = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "  ])\n",
        "\n",
        "  augment2 = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(p = 0.25),\n",
        "      transforms.RandomVerticalFlip(p = 0.25),\n",
        "      transforms.RandomRotation(15, p = 0.25),\n",
        "      transforms.RandomRotation([90, 180, 270], p = 0.25),\n",
        "  ])\n",
        "\n",
        "  for i, img in enumerate(imgs_copy):\n",
        "    imgs_copy[i] = augment1(imgs_copy[i])\n",
        "    imgs_copy[i] = augment2(imgs_copy[i])\n",
        "\n",
        "  final_imgs = imgs + imgs_copy\n",
        "\n",
        "  return final_imgs\n",
        "\n",
        "\n",
        "def preprocess(imgs):\n",
        "\n",
        "  new_imgs = []\n",
        "  for i, img in enumerate(imgs):\n",
        "    temp_img = (np.array(img, dtype = int)/255)\n",
        "    if(len(temp_img.shape) != 3):\n",
        "      print(\"smit\")\n",
        "    else:\n",
        "      new_imgs.append(temp_img)\n",
        "    # print(i, \"--\", imgs[i].shape)\n",
        "\n",
        "\n",
        "  return new_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijpd20R-4yNw"
      },
      "source": [
        "Split into labels and imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HvZzhc6C4xmM"
      },
      "outputs": [],
      "source": [
        "def data_split(arr1, arr2):\n",
        "  # 1 for arr1\n",
        "  # 0 for arr2\n",
        "\n",
        "  tot_data = []\n",
        "  for el in arr1:\n",
        "    tot_data.append((el, 1))\n",
        "  for el in arr2:\n",
        "    tot_data.append((el, 0))\n",
        "  \n",
        "  all_imgs = [i[0] for i in tot_data]\n",
        "  all_labels = [i[1] for i in tot_data]\n",
        "\n",
        "  return all_imgs, all_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEsj9FkG7WSp"
      },
      "source": [
        "Dataset Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NiydfJuJ7TLX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "\n",
        "class Dataloader(data.Dataset):\n",
        "  def __init__(self, imgs, labels):\n",
        "    super(Dataloader).__init__()\n",
        "\n",
        "    self.imgs = torch.from_numpy(imgs)\n",
        "    self.labels = labels\n",
        "    self.len = len(self.labels)\n",
        "\n",
        "    pos = np.sum(self.labels)\n",
        "    neg = len(self.labels) - pos\n",
        "    self.weights = torch.FloatTensor([1, neg / pos])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    label = self.labels[idx]\n",
        "    if label == 1:\n",
        "        label = torch.FloatTensor([0, 1])\n",
        "    elif label == 0:\n",
        "        label = torch.FloatTensor([1, 0])\n",
        "    return (self.imgs[idx], label, self.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfSLzIHX9snX"
      },
      "source": [
        "Function to initialize weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jplYIkFo7X2t"
      },
      "outputs": [],
      "source": [
        "def init_weights(model):\n",
        "  for name, param in model.named_parameters():\n",
        "    nn.init.uniform_(param.data, -0.08, 0.08)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRJ1LLlygVr"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p2X4u_ZjygBR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# hook the feature extractor\n",
        "feature_blobs = []\n",
        "\n",
        "def hook_feature(output):\n",
        "    global feature_blobs\n",
        "    feature_blobs.append(output.data.cpu().numpy())\n",
        "\n",
        "class ICNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = models.vgg16(pretrained=True)\n",
        "        # self.first_conv_layer = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1, dilation=1, groups=1, bias=True)\n",
        "        # self.first_conv_layer.extend(list(self.pretrained_model.features))  \n",
        "        # self.features= nn.Sequential(*self.first_conv_layer ) \n",
        "\n",
        "        self.pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifer1 = nn.Linear(512, 64)\n",
        "        self.classifer2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x, mode = \"train\"):\n",
        "        x = torch.squeeze(x, dim=0)\n",
        "        print(x.shape) \n",
        "        # x = self.first_conv_layer(x)\n",
        "        features = self.pretrained_model.features(x)\n",
        "        if mode == \"test\":\n",
        "          hook_feature(features)\n",
        "        # self.pretrained_model._modules.get('features').register_forward_hook(hook_feature);\n",
        "\n",
        "        # print('1: ', x.shape)\n",
        "        pooled_features = self.pooling_layer(features)\n",
        "        # print('2: ', pooled_features.shape)\n",
        "        pooled_features = pooled_features.view(pooled_features.size()[0], -1)\n",
        "        # print('3: ', pooled_features.shape)\n",
        "        # flattened_features = torch.max(pooled_features, 0, keepdim=True)[0]\n",
        "        # print('3: ', flattened_features.shape)\n",
        "        # flattened_features = torch.squeeze(flattened_features, dim=0)\n",
        "        # print('4: ', flattened_features.shape)\n",
        "        fc_out1 = self.classifer1(pooled_features)\n",
        "        # print('FCOUT: ' ,fc_out1.shape)\n",
        "\n",
        "        output = self.classifer2(fc_out1)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqeItGkvZgCC"
      },
      "source": [
        "Generate Class Activation Maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R12d8nbMZfmc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def returnCAM(feature_conv, weight_sigmoid, class_idx):\n",
        "    size_upsample = (224, 224)\n",
        "    bz, nc, h, w = feature_conv.shape\n",
        "    print(\"feature conv: \", feature_conv.shape)\n",
        "    print(\"weight_sigmoid: \", weight_sigmoid.shape)\n",
        "    print(\"class_idx: \", class_idx.shape)\n",
        "    slice_cams = []\n",
        "    for s in range(bz):\n",
        "        for idx in class_idx:\n",
        "            cam = weight_sigmoid[idx].dot(feature_conv[s].reshape((nc, h*w)))\n",
        "            cam = cam.reshape(h, w)\n",
        "            cam = cam - np.min(cam)\n",
        "            cam_img = cam / np.max(cam)\n",
        "            cam_img = np.uint8(255 * cam_img)\n",
        "            slice_cams.append(cv2.resize(cam_img, size_upsample))\n",
        "    return slice_cams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnQpoRVVzxfz"
      },
      "source": [
        "Function to Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFeKz0cbzxDk",
        "outputId": "75802a14-8544-47dd-886c-642e71c80bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: TensorboardX in /usr/local/lib/python3.10/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from TensorboardX) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install TensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GlP3Y_ID0PBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import os\n",
        "import torch.utils.data as Data\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"\n",
        "To view the data written by tensorboardX\n",
        "tensorboard --logdir <path of logs directory>\n",
        "In my case, pathdir = 'logs/'\n",
        "\"\"\"\n",
        "\n",
        "def train(X_train, y_train):\n",
        "\n",
        "  data = Dataloader(np.array(X_train), np.array(y_train))\n",
        "  logger = SummaryWriter(os.path.join(HOME, LOG_DIR, TIME + ': Train'))\n",
        "\n",
        "  model = ICNN()\n",
        "  model.apply(init_weights)\n",
        "\n",
        "  train_loader = Data.DataLoader(Data.Subset(data, range(int(opt['train_len']*len(y_train)))), batch_size = opt['batch_size'],shuffle = True)\n",
        "  val_loader = Data.DataLoader(Data.Subset(data, range(int(opt['train_len']*len(y_train)),int(opt['train_len']*len(y_train) + opt['val_len']*len(y_train)))), batch_size = opt['batch_size'], shuffle = True)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr = opt['lr'])\n",
        "  model.train()\n",
        "  model.to(DEVICE)\n",
        "\n",
        "  print('-----------------BEGIN TRAINING-------------------')\n",
        "\n",
        "  for epoch in range(opt['epochs']):\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "    losses = []\n",
        "    auc_vec = []\n",
        "    train_corr = 0.0\n",
        "    itr = 0\n",
        "    model.train()\n",
        "    \n",
        "    for img, label, weight in tqdm(train_loader, ascii = True, desc = 'Train ' + str(epoch+1)):\n",
        "      img = img.permute(0,3,1,2).type(torch.cuda.FloatTensor).to(DEVICE)\n",
        "      label = label.to(DEVICE)\n",
        "      weight = weight.to(DEVICE)\n",
        "\n",
        "      out = model(img)\n",
        "      loss = torch.nn.BCEWithLogitsLoss(weight)(out, label)\n",
        "      # 0 for not infected [1,0]\n",
        "      # 1 for infected [0,1]\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      prob = torch.sigmoid(out)\n",
        "\n",
        "      for i in range(label.shape[0]): # first index indicates the prob of the image being infected\n",
        "        y_trues.append(int(label[i][1]))\n",
        "        y_preds.append(prob[i][1].item())\n",
        "\n",
        "      try:\n",
        "        auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "      except:\n",
        "        auc = 0.5\n",
        "      auc_vec.append(auc)\n",
        "\n",
        "      logger.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + itr)\n",
        "      logger.add_scalar('Train/AUC', auc, epoch * len(train_loader) + itr)\n",
        "      print(\"LOSS: \", loss.item())\n",
        "\n",
        "      y_preds_rounded = [0 if i<auc else 1 for i in y_preds]\n",
        "      if(itr == 0):\n",
        "        print(\"Y_ROUNDED: \", y_preds_rounded)\n",
        "        print(\"Y_TRUES: \", y_trues)\n",
        "\n",
        "      for i in range(label.shape[0]):\n",
        "        train_corr += int(y_trues[i] == y_preds_rounded[i])\n",
        "        itr+=1\n",
        "\n",
        "      # itr+=label.shape[0]\n",
        "    \n",
        "    logger.add_scalar('Training_accuracy', sum(losses)/itr, epoch)\n",
        "    print('EPOCH_CORR: ', epoch, '---', train_corr/itr)\n",
        "\n",
        "    print(\"AUC TRAIN final: \", sum(auc_vec)/len(auc_vec))\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    \n",
        "    print('----------------BEGIN VALIDATION---------------------')\n",
        "    itr = 0\n",
        "    val_losses = []\n",
        "    val_corr = 0.0\n",
        "    val_y_preds = []\n",
        "    val_y_trues = []\n",
        "    auc_vec = []\n",
        "\n",
        "    model.eval()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for img, label, weight in tqdm(val_loader, ascii = True, desc = 'Validation ' + str(epoch+1)):\n",
        "        # img = img.unsqueeze(1).type(torch.cuda.FloatTensor).to(DEVICE)\n",
        "        img = img.permute(0,3,1,2).type(torch.cuda.FloatTensor).to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        weight = weight.to(DEVICE)\n",
        "\n",
        "        out = model(img)\n",
        "        loss = torch.nn.BCEWithLogitsLoss(weight)(out, label)\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "        sig_out = torch.sigmoid(out)\n",
        "\n",
        "        for i in range(label.shape[0]):\n",
        "          val_y_trues.append(int(label[i][1]))\n",
        "          val_y_preds.append(sig_out[i][1].item())\n",
        "\n",
        "        try:\n",
        "          auc = metrics.roc_auc_score(val_y_trues, val_y_preds)\n",
        "        except:\n",
        "          auc = 0.5\n",
        "        auc_vec.append(auc)\n",
        "\n",
        "        logger.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + itr)\n",
        "        logger.add_scalar('Train/AUC', auc, epoch * len(train_loader) + itr)\n",
        "        print(\"AUC: \", auc)\n",
        "\n",
        "        y_preds_rounded = [0 if i<auc else 1 for i in val_y_preds]\n",
        "        \n",
        "        for i in range(len(val_y_trues)):\n",
        "          val_corr += int(val_y_trues[i] == y_preds_rounded[i])\n",
        "          itr+=1\n",
        "        break\n",
        "\n",
        "        # itr+=label.shape[0]\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      logger.add_scalar('Validation_loss', sum(val_losses)/itr, epoch)\n",
        "      print('EPOCH: ', epoch, '---', sum(val_losses)/itr)\n",
        "      logger.add_scalar('Validation_accuracy', val_corr/itr, epoch)\n",
        "      print('EPOCH_CORR: ', epoch, '---', val_corr/itr, epoch)\n",
        "\n",
        "    print(\"AUC final: \", sum(auc_vec)/len(auc_vec))\n",
        "  \n",
        "  print('TRAINING DONE')\n",
        "  torch.save({'state_dict': model.state_dict()}, 'ICNN.pt')\n",
        "  logger.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpz3X1Kx004N"
      },
      "source": [
        "Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WemJC64J0j7W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.utils.data as Data\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def test(X_test, y_test):\n",
        "  model = ICNN()\n",
        "  checkpoint = torch.load('ICNN.pt')\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  #running_model = torch.load('multi_cnn.pt', map_location = device)\n",
        "\n",
        "  test_data = Dataloader(np.array(X_test), np.array(y_test))\n",
        "  logger = SummaryWriter(os.path.join(HOME, LOG_DIR, TIME + ': Test'))\n",
        "\n",
        "\n",
        "  test_loader = Data.DataLoader(Data.Subset(test_data,range(len(test_data))), opt['batch_size'],shuffle = True)\n",
        "  model.to(DEVICE)\n",
        "\n",
        "  y_preds = []\n",
        "  y_trues = []\n",
        "  losses = []\n",
        "  test_corr = 0.0\n",
        "  itr = 0\n",
        "\n",
        "  for img, label, weight in tqdm(test_loader, ascii = True, desc = 'Test'):\n",
        "\n",
        "    img = img.permute(0,3,1,2).type(torch.cuda.FloatTensor).to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "    weight = weight.to(DEVICE)\n",
        "\n",
        "    params = list(model.parameters())\n",
        "    final_params = torch.matmul(params[-2], params[-4])\n",
        "    weight_sigmoid = np.squeeze(final_params.data.cpu().numpy())\n",
        "\n",
        "    output = model(img, \"test\")\n",
        "\n",
        "    sig_out = torch.sigmoid(output)\n",
        "    probs, idx = sig_out.sort(0, True)\n",
        "\n",
        "    probs = probs.cpu().numpy()\n",
        "    idx = idx.cpu().numpy()\n",
        "    new_idx = np.array([0,1])\n",
        "\n",
        "    slice_cams = returnCAM(feature_blobs[-1], weight_sigmoid, new_idx)\n",
        "   \n",
        "    for s in tqdm(range(label.shape[0]), leave=False):\n",
        "      img = img[s]\n",
        "      new_img = img.permute(1,2,0)\n",
        "      new_img = new_img.cpu().numpy()\n",
        "      for i, cam in enumerate(slice_cams):\n",
        "\n",
        "        heatmap = (cv2.cvtColor(cv2.applyColorMap(\n",
        "                        cv2.resize(slice_cams[s][i], (224, 224)),\n",
        "                        cv2.COLORMAP_JET), \n",
        "                              cv2.COLOR_BGR2RGB)\n",
        "                  )\n",
        "        result = heatmap * 0.3 + new_img * 0.5  \n",
        "        \n",
        "        pil_img_cam = Image.fromarray(np.uint8(result))\n",
        "        # plt.subplot(1, 2, i + 1)\n",
        "  \n",
        "        plt.imshow(np.array(pil_img_cam))\n",
        "        plt.title('Not Infected' if i==0 else 'Infected')\n",
        "\n",
        "\n",
        "    for i in range(label.shape[0]):\n",
        "      y_trues.append(int(label[i][1]))\n",
        "      y_preds.append(sig_out[i][1].item())\n",
        "\n",
        "    try:\n",
        "      auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "    except:\n",
        "      auc = 0.5\n",
        "\n",
        "    logger.add_scalar('test/AUC', auc, len(test_loader) + itr)\n",
        "    print(\"AUC: \", auc)\n",
        "\n",
        "    y_preds_rounded = [0 if i<auc else 1 for i in y_preds]\n",
        "\n",
        "    for i in range(len(y_trues)):\n",
        "      test_corr += int(y_trues[i] == y_preds_rounded[i])\n",
        "      itr+=1\n",
        "      \n",
        "    logger.add_scalar('testing_loss', losses/itr)\n",
        "    print('LOSS: ', '---', losses/itr)\n",
        "    logger.add_scalar('testing_accuracy', test_corr.double()/itr,)\n",
        "    print('ACCURACY: ', '---', test_corr.double()/itr)\n",
        "    \n",
        "  print('--------------------------------------TEST DONE-------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5L7EajO3S0W"
      },
      "outputs": [],
      "source": [
        "def run(mode = \"train\", to_augment = False, only_train = False):\n",
        "    \n",
        "    print(\"MODE: \", mode)\n",
        "    root_dir = os.path.join(HOME, 'data', mode, 'infected')\n",
        "    print(root_dir)\n",
        "    mode_infected = upload_imgs(root_dir)\n",
        "    \n",
        "    root_dir = os.path.join(HOME, 'data', mode, 'notinfected')\n",
        "    mode_notinfected = upload_imgs(root_dir)\n",
        "\n",
        "    mode_infected_p = []\n",
        "    mode_notinfected_p = []\n",
        "    if(to_augment == True):\n",
        "        mode_infected_p = preprocess(augment(mode_infected))\n",
        "        # mode_notinfected_p = preprocess(augment(mode_notinfected))\n",
        "    else:\n",
        "      mode_infected_p = preprocess(mode_infected)\n",
        "      # mode_notinfected_p = preprocess(mode_notinfected)\n",
        "\n",
        "    mode_notinfected_p = []\n",
        "    mode_x, mode_y = data_split(mode_infected_p, mode_notinfected_p)\n",
        "\n",
        "    if(mode == \"train\"):\n",
        "      train(mode_x, mode_y)\n",
        "    elif(mode == \"test\"):\n",
        "      test(mode_x[:2000], mode_y[:2000])\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUPzTO5I02vY"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    LOG_DIR = 'logs'\n",
        "    HOME = '/content/drive/MyDrive'\n",
        "    SAVE_DIR = 'save'\n",
        "    TIME = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    opt = {\n",
        "      'batch_size': 16,\n",
        "      'lr': 0.01,\n",
        "      'epochs': 10,\n",
        "      'train_len': 0.8,\n",
        "      'val_len': 0.2,\n",
        "      'out': 4,\n",
        "      'activation': 'RELU',\n",
        "    } \n",
        "\n",
        "    run(\"train\")\n",
        "    print(\"Smit Training Done\")\n",
        "\n",
        "    run(\"test\")\n",
        "    print(\"Smit Testing done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODm98W2W0tEQ"
      },
      "source": [
        "Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgLcJnia0sYW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from tensorflow.keras.layers import Lambda\n",
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def calculate_thresh(imp_arr, percent):\n",
        "  #gen_arr.sort(reverse = True)\n",
        "  imp_arr.sort(reverse = True)\n",
        "  ind = len(imp_arr)*percent\n",
        "  return imp_arr[int(ind)]\n",
        "\n",
        "\n",
        "def calculate_TMR(gen_arr, thresh):\n",
        "  return (sum(i>=thresh for i in gen_arr))/len(gen_arr)\n",
        "\n",
        "\n",
        "def normalise(gen_arr, imp_arr):\n",
        "  scaler = MinMaxScaler()\n",
        "  combined_list = []\n",
        "  combined_list.extend(gen_arr)\n",
        "  combined_list.extend(imp_arr)\n",
        "\n",
        "  scaled_list = scaler.fit_transform(np.array(combined_list).reshape(-1,1)).tolist()\n",
        "  half = len(scaled_list)//2\n",
        "  return scaled_list[:half], scaled_list[half:]\n",
        "\n",
        "\n",
        "def cos_similar(A, B):\n",
        "  cos_sim=np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
        "  return cos_sim\n",
        "\n",
        "\n",
        "def save_to_csv(gen, imp):\n",
        "  header = ['Normalized Score', 'Label']\n",
        "  file_path = '/content/drive/MyDrive/' #nd = no dilation, d = dilation\n",
        "  fle = Path(file_path)\n",
        "  fle.touch(exist_ok=True)\n",
        "  gen_save_arr = [[i,1] for i in gen]\n",
        "  imp_save_arr = [[i,0] for i in imp]\n",
        "  #if not os.path.exists(file_path):\n",
        "    # os.mkdir(file_path)\n",
        "  with open(file_path, 'a+', encoding = 'utf-8', newline ='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(gen_save_arr)\n",
        "    writer.writerows(imp_save_arr)\n",
        "\n",
        "\n",
        "def save_score(score):\n",
        "  file_path = '/content/drive/MyDrive/scores.csv'\n",
        "  header = ['Model', 'Score', 'AF', 'OutNodes', 'BatchSz', 'LR']\n",
        "  if not os.path.exists(file_path):\n",
        "    with open(file_path, 'a+', encoding = 'utf-8', newline = '') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header)\n",
        "\n",
        "  fle = Path(file_path)\n",
        "  fle.touch(exist_ok=True)\n",
        "\n",
        "  data = [opt['model'], score, opt['activation'], opt['out'], opt['batch_size'], opt['lr']]\n",
        "\n",
        "  with open(file_path, 'a+', encoding = 'utf-8', newline = '') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)\n",
        "\n",
        "\n",
        "#save_to_csv([1,2,3,4,5], [6,7,8,9,0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
